{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![下载Notebook](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.4.0/resource/_static/logo_notebook.svg)](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/r2.4.0/tutorials/zh_cn/generative/mindspore_gan.ipynb)&emsp;[![下载样例代码](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.4.0/resource/_static/logo_download_code.svg)](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/r2.4.0/tutorials/zh_cn/generative/mindspore_gan.py)&emsp;[![查看源文件](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.4.0/resource/_static/logo_source.svg)](https://gitee.com/mindspore/docs/blob/r2.4.0/tutorials/source_zh_cn/generative/gan.ipynb)\n",
    "\n",
    "# GAN图像生成\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型简介\n",
    "\n",
    "生成式对抗网络(Generative Adversarial Networks，GAN)是一种生成式机器学习模型，是近年来复杂分布上无监督学习最具前景的方法之一。\n",
    "\n",
    "最初，GAN由Ian J. Goodfellow于2014年发明，并在论文[Generative Adversarial Nets](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf)中首次进行了描述，其主要由两个不同的模型共同组成——生成器(Generative Model)和判别器(Discriminative Model)：\n",
    "\n",
    "- 生成器的任务是生成看起来像训练图像的“假”图像；\n",
    "- 判别器需要判断从生成器输出的图像是真实的训练图像还是虚假的图像。\n",
    "\n",
    "GAN通过设计生成模型和判别模型这两个模块，使其互相博弈学习产生了相当好的输出。\n",
    "\n",
    "GAN模型的核心在于提出了通过对抗过程来估计生成模型这一全新框架。在这个框架中，将会同时训练两个模型——捕捉数据分布的生成模型 $G$ 和估计样本是否来自训练数据的判别模型 $D$ 。\n",
    "\n",
    "在训练过程中，生成器会不断尝试通过生成更好的假图像来骗过判别器，而判别器在这过程中也会逐步提升判别能力。这种博弈的平衡点是，当生成器生成的假图像和训练数据图像的分布完全一致时，判别器拥有50%的真假判断置信度。\n",
    "\n",
    "用 $x$ 代表图像数据，用 $D(x)$表示判别器网络给出图像判定为真实图像的概率。在判别过程中，$D(x)$ 需要处理作为二进制文件的大小为 $1\\times 28\\times 28$ 的图像数据。当 $x$ 来自训练数据时，$D(x)$ 数值应该趋近于 $1$ ；而当 $x$ 来自生成器时，$D(x)$ 数值应该趋近于 $0$ 。因此 $D(x)$ 也可以被认为是传统的二分类器。\n",
    "\n",
    "用 $z$ 代表标准正态分布中提取出的隐码(隐向量)，用 $G(z)$：表示将隐码(隐向量) $z$ 映射到数据空间的生成器函数。函数 $G(z)$ 的目标是将服从高斯分布的随机噪声 $z$ 通过生成网络变换为近似于真实分布 $p_{data}(x)$ 的数据分布，我们希望找到 $θ$ 使得 $p_{G}(x;\\theta)$ 和 $p_{data}(x)$ 尽可能的接近，其中 $\\theta$ 代表网络参数。\n",
    "\n",
    "$D(G(z))$ 表示生成器 $G$ 生成的假图像被判定为真实图像的概率，如[Generative Adversarial Nets](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf)中所述，$D$ 和 $G$ 在进行一场博弈，$D$ 想要最大程度的正确分类真图像与假图像，也就是参数 $\\log D(x)$；而 $G$ 试图欺骗 $D$ 来最小化假图像被识别到的概率，也就是参数 $\\log(1−D(G(z)))$。因此GAN的损失函数为：\n",
    "\n",
    "$$\n",
    "\\min\\limits_{G}\\max\\limits_{D} V(D,G)=E_{x\\sim p_{data}\\;\\,(x)}[\\log D(x)]+E_{z\\sim p_{z}\\,(z)}[\\log (1-D(G(z)))]\n",
    "$$\n",
    "\n",
    "从理论上讲，此博弈游戏的平衡点是$p_{G}(x;\\theta) = p_{data}(x)$，此时判别器会随机猜测输入是真图像还是假图像。下面我们简要说明生成器和判别器的博弈过程：\n",
    "\n",
    "1. 在训练刚开始的时候，生成器和判别器的质量都比较差，生成器会随机生成一个数据分布。\n",
    "2. 判别器通过求取梯度和损失函数对网络进行优化，将靠近真实数据分布的数据判定为1，将靠近生成器生成出来数据分布的数据判定为0。\n",
    "3. 生成器通过优化，生成出更加贴近真实数据分布的数据。\n",
    "4. 生成器所生成的数据和真实数据达到相同的分布，此时判别器的输出为1/2。\n",
    "\n",
    "![gan](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.4.0/tutorials/source_zh_cn/cv/images/gan_image.png)\n",
    "\n",
    "在上图中，蓝色虚线表示判别器，黑色虚线表示真实数据分布，绿色实线表示生成器生成的虚假数据分布，$z$ 表示隐码，$x$ 表示生成的虚假图像 $G(z)$。该图片来源于[Generative Adversarial Nets](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf)。详细的训练方法介绍见原论文。\n",
    "\n",
    "## 数据集\n",
    "\n",
    "### 数据集简介\n",
    "\n",
    "[MNIST手写数字数据集](http://yann.lecun.com/exdb/mnist/)是NIST数据集的子集，共有70000张手写数字图片，包含60000张训练样本和10000张测试样本，数字图片为二进制文件，图片大小为28\\*28，单通道。图片已经预先进行了尺寸归一化和中心化处理。\n",
    "\n",
    "本案例将使用MNIST手写数字数据集来训练一个生成式对抗网络，使用该网络模拟生成手写数字图片。\n",
    "\n",
    "### 数据集下载\n",
    "\n",
    "使用`download`接口下载数据集，并将下载后的数据集自动解压到当前目录下。数据下载之前需要使用`pip install download`安装`download`包。\n",
    "\n",
    "下载解压后的数据集目录结构如下：\n",
    "\n",
    "```text\n",
    "./MNIST_Data/\n",
    "├─ train\n",
    "│ ├─ train-images-idx3-ubyte\n",
    "│ └─ train-labels-idx1-ubyte\n",
    "└─ test\n",
    "   ├─ t10k-images-idx3-ubyte\n",
    "   └─ t10k-labels-idx1-ubyte\n",
    "```\n",
    "\n",
    "数据下载的代码如下：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据下载\n",
    "from download import download\n",
    "\n",
    "url = \"https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/MNIST_Data.zip\"\n",
    "download(url, \".\", kind=\"zip\", replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据加载\n",
    "\n",
    "使用MindSpore自己的`MnistDatase`接口，读取和解析MNIST数据集的源文件构建数据集。然后对数据进行一些前处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mindspore.dataset as ds\n",
    "import mindspore\n",
    "mindspore.set_context(device_target=\"Ascend\")\n",
    "\n",
    "batch_size = 128\n",
    "latent_size = 100  # 隐码的长度\n",
    "\n",
    "train_dataset = ds.MnistDataset(dataset_dir='./MNIST_Data/train')\n",
    "test_dataset = ds.MnistDataset(dataset_dir='./MNIST_Data/test')\n",
    "\n",
    "def data_load(dataset):\n",
    "    dataset1 = ds.GeneratorDataset(dataset, [\"image\", \"label\"], shuffle=True, python_multiprocessing=False)\n",
    "    # 数据增强\n",
    "    mnist_ds = dataset1.map(\n",
    "        operations=lambda x: (x.astype(\"float32\"), np.random.normal(size=latent_size).astype(\"float32\")),\n",
    "        output_columns=[\"image\", \"latent_code\"])\n",
    "    mnist_ds = mnist_ds.project([\"image\", \"latent_code\"])\n",
    "\n",
    "    # 批量操作\n",
    "    mnist_ds = mnist_ds.batch(batch_size, True)\n",
    "\n",
    "    return mnist_ds\n",
    "\n",
    "mnist_ds = data_load(train_dataset)\n",
    "\n",
    "iter_size = mnist_ds.get_dataset_size()\n",
    "print('Iter size: %d' % iter_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集可视化\n",
    "\n",
    "通过`create_dict_iterator`函数将数据转换成字典迭代器，然后使用`matplotlib`模块可视化部分训练数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_iter = next(mnist_ds.create_dict_iterator(output_numpy=True))\n",
    "figure = plt.figure(figsize=(3, 3))\n",
    "cols, rows = 5, 5\n",
    "for idx in range(1, cols * rows + 1):\n",
    "    image = data_iter['image'][idx]\n",
    "    figure.add_subplot(rows, cols, idx)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 隐码构造\n",
    "\n",
    "为了跟踪生成器的学习进度，我们在训练的过程中的每轮迭代结束后，将一组固定的遵循高斯分布的隐码`test_noise`输入到生成器中，通过固定隐码所生成的图像效果来评估生成器的好坏。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from mindspore import Tensor, dtype\n",
    "\n",
    "# 利用随机种子创建一批隐码\n",
    "np.random.seed(2323)\n",
    "test_noise = Tensor(np.random.normal(size=(25, 100)), dtype.float32)\n",
    "random.shuffle(test_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型构建\n",
    "\n",
    "本案例实现中所搭建的 GAN 模型结构与原论文中提出的 GAN 结构大致相同，但由于所用数据集 MNIST 为单通道小尺寸图片，可识别参数少，便于训练，我们在判别器和生成器中采用全连接网络架构和 `ReLU` 激活函数即可达到令人满意的效果，且省略了原论文中用于减少参数的 `Dropout` 策略和可学习激活函数 `Maxout`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成器\n",
    "\n",
    "生成器 `Generator` 的功能是将隐码映射到数据空间。由于数据是图像，这一过程也会创建与真实图像大小相同的灰度图像(或 RGB 彩色图像)。在本案例演示中，该功能通过五层 `Dense` 全连接层来完成的，每层都与 `BatchNorm1d` 批归一化层和 `ReLU` 激活层配对，输出数据会经过 `Tanh` 函数，使其返回 [-1,1] 的数据范围内。注意实例化生成器之后需要修改参数的名称，不然静态图模式下会报错。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import nn\n",
    "import mindspore.ops as ops\n",
    "\n",
    "img_size = 28  # 训练图像长（宽）\n",
    "\n",
    "class Generator(nn.Cell):\n",
    "    def __init__(self, latent_size, auto_prefix=True):\n",
    "        super(Generator, self).__init__(auto_prefix=auto_prefix)\n",
    "        self.model = nn.SequentialCell()\n",
    "        # [N, 100] -> [N, 128]\n",
    "        # 输入一个100维的0～1之间的高斯分布，然后通过第一层线性变换将其映射到256维\n",
    "        self.model.append(nn.Dense(latent_size, 128))\n",
    "        self.model.append(nn.ReLU())\n",
    "        # [N, 128] -> [N, 256]\n",
    "        self.model.append(nn.Dense(128, 256))\n",
    "        self.model.append(nn.BatchNorm1d(256))\n",
    "        self.model.append(nn.ReLU())\n",
    "        # [N, 256] -> [N, 512]\n",
    "        self.model.append(nn.Dense(256, 512))\n",
    "        self.model.append(nn.BatchNorm1d(512))\n",
    "        self.model.append(nn.ReLU())\n",
    "        # [N, 512] -> [N, 1024]\n",
    "        self.model.append(nn.Dense(512, 1024))\n",
    "        self.model.append(nn.BatchNorm1d(1024))\n",
    "        self.model.append(nn.ReLU())\n",
    "        # [N, 1024] -> [N, 784]\n",
    "        # 经过线性变换将其变成784维\n",
    "        self.model.append(nn.Dense(1024, img_size * img_size))\n",
    "        # 经过Tanh激活函数是希望生成的假的图片数据分布能够在-1～1之间\n",
    "        self.model.append(nn.Tanh())\n",
    "\n",
    "    def construct(self, x):\n",
    "        img = self.model(x)\n",
    "        return ops.reshape(img, (-1, 1, 28, 28))\n",
    "\n",
    "net_g = Generator(latent_size)\n",
    "net_g.update_parameters_name('generator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 判别器\n",
    "\n",
    "如前所述，判别器 `Discriminator` 是一个二分类网络模型，输出判定该图像为真实图的概率。主要通过一系列的 `Dense` 层和 `LeakyReLU` 层对其进行处理，最后通过 `Sigmoid` 激活函数，使其返回 [0, 1] 的数据范围内，得到最终概率。注意实例化判别器之后需要修改参数的名称，不然静态图模式下会报错。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 判别器\n",
    "class Discriminator(nn.Cell):\n",
    "    def __init__(self, auto_prefix=True):\n",
    "        super().__init__(auto_prefix=auto_prefix)\n",
    "        self.model = nn.SequentialCell()\n",
    "        # [N, 784] -> [N, 512]\n",
    "        self.model.append(nn.Dense(img_size * img_size, 512))  # 输入特征数为784，输出为512\n",
    "        self.model.append(nn.LeakyReLU())  # 默认斜率为0.2的非线性映射激活函数\n",
    "        # [N, 512] -> [N, 256]\n",
    "        self.model.append(nn.Dense(512, 256))  # 进行一个线性映射\n",
    "        self.model.append(nn.LeakyReLU())\n",
    "        # [N, 256] -> [N, 1]\n",
    "        self.model.append(nn.Dense(256, 1))\n",
    "        self.model.append(nn.Sigmoid())  # 二分类激活函数，将实数映射到[0,1]\n",
    "\n",
    "    def construct(self, x):\n",
    "        x_flat = ops.reshape(x, (-1, img_size * img_size))\n",
    "        return self.model(x_flat)\n",
    "\n",
    "net_d = Discriminator()\n",
    "net_d.update_parameters_name('discriminator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失函数和优化器\n",
    "\n",
    "定义了 `Generator` 和 `Discriminator` 后，损失函数使用MindSpore中二进制交叉熵损失函数`BCELoss` ；这里生成器和判别器都是使用`Adam`优化器，但是需要构建两个不同名称的优化器，分别用于更新两个模型的参数，详情见下文代码。注意优化器的参数名称也需要修改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0002  # 学习率\n",
    "\n",
    "# 损失函数\n",
    "adversarial_loss = nn.BCELoss(reduction='mean')\n",
    "\n",
    "# 优化器\n",
    "optimizer_d = nn.Adam(net_d.trainable_params(), learning_rate=lr, beta1=0.5, beta2=0.999)\n",
    "optimizer_g = nn.Adam(net_g.trainable_params(), learning_rate=lr, beta1=0.5, beta2=0.999)\n",
    "optimizer_g.update_parameters_name('optim_g')\n",
    "optimizer_d.update_parameters_name('optim_d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "\n",
    "训练分为两个主要部分。\n",
    "\n",
    "第一部分是训练判别器。训练判别器的目的是最大程度地提高判别图像真伪的概率。按照原论文的方法，通过提高其随机梯度来更新判别器，最大化 $log D(x) + log(1 - D(G(z))$ 的值。\n",
    "\n",
    "第二部分是训练生成器。如论文所述，最小化 $log(1 - D(G(z)))$ 来训练生成器，以产生更好的虚假图像。\n",
    "\n",
    "在这两个部分中，分别获取训练过程中的损失，并在每轮迭代结束时进行测试，将隐码批量推送到生成器中，以直观地跟踪生成器 `Generator` 的训练效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import mindspore as ms\n",
    "from mindspore import Tensor, save_checkpoint\n",
    "\n",
    "total_epoch = 200  # 训练周期数\n",
    "batch_size = 128  # 用于训练的训练集批量大小\n",
    "\n",
    "# 加载预训练模型的参数\n",
    "pred_trained = False\n",
    "pred_trained_g = './result/checkpoints/Generator99.ckpt'\n",
    "pred_trained_d = './result/checkpoints/Discriminator99.ckpt'\n",
    "\n",
    "checkpoints_path = \"./result/checkpoints\"  # 结果保存路径\n",
    "image_path = \"./result/images\"  # 测试结果保存路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore\n",
    "mindspore.set_context(device_target=\"Ascend\")\n",
    "\n",
    "# 生成器计算损失过程\n",
    "def generator_forward(test_noises):\n",
    "    fake_data = net_g(test_noises)\n",
    "    fake_out = net_d(fake_data)\n",
    "    loss_g = adversarial_loss(fake_out, ops.ones_like(fake_out))\n",
    "    return loss_g\n",
    "\n",
    "# 判别器计算损失过程\n",
    "def discriminator_forward(real_data, test_noises):\n",
    "    fake_data = net_g(test_noises)\n",
    "    fake_out = net_d(fake_data)\n",
    "    real_out = net_d(real_data)\n",
    "    real_loss = adversarial_loss(real_out, ops.ones_like(real_out))\n",
    "    fake_loss = adversarial_loss(fake_out, ops.zeros_like(fake_out))\n",
    "    loss_d = real_loss + fake_loss\n",
    "    return loss_d\n",
    "\n",
    "# 梯度方法\n",
    "grad_g = ms.value_and_grad(generator_forward, None, net_g.trainable_params())\n",
    "grad_d = ms.value_and_grad(discriminator_forward, None, net_d.trainable_params())\n",
    "\n",
    "def train_step(real_data, latent_code):\n",
    "    # 计算判别器损失和梯度\n",
    "    loss_d, grads_d = grad_d(real_data, latent_code)\n",
    "    optimizer_d(grads_d)\n",
    "    loss_g, grads_g = grad_g(latent_code)\n",
    "    optimizer_g(grads_g)\n",
    "\n",
    "    return loss_d, loss_g\n",
    "\n",
    "# 保存生成的test图像\n",
    "def save_imgs(gen_imgs1, idx):\n",
    "    for i3 in range(gen_imgs1.shape[0]):\n",
    "        plt.subplot(5, 5, i3 + 1)\n",
    "        plt.imshow(gen_imgs1[i3, 0, :, :] / 2 + 0.5, cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.savefig(image_path + \"/test_{}.png\".format(idx))\n",
    "\n",
    "# 设置参数保存路径\n",
    "os.makedirs(checkpoints_path, exist_ok=True)\n",
    "# 设置中间过程生成图片保存路径\n",
    "os.makedirs(image_path, exist_ok=True)\n",
    "\n",
    "net_g.set_train()\n",
    "net_d.set_train()\n",
    "\n",
    "# 储存生成器和判别器loss\n",
    "losses_g, losses_d = [], []\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    start = time.time()\n",
    "    for (iter, data) in enumerate(mnist_ds):\n",
    "        start1 = time.time()\n",
    "        image, latent_code = data\n",
    "        image = (image - 127.5) / 127.5  # [0, 255] -> [-1, 1]\n",
    "        image = image.reshape(image.shape[0], 1, image.shape[1], image.shape[2])\n",
    "        d_loss, g_loss = train_step(image, latent_code)\n",
    "        end1 = time.time()\n",
    "        if iter % 100 == 0:\n",
    "            print(f\"Epoch:[{int(epoch):>3d}/{int(total_epoch):>3d}], \"\n",
    "                  f\"step:[{int(iter):>4d}/{int(iter_size):>4d}], \"\n",
    "                  f\"loss_d:{d_loss.asnumpy():>4f} , \"\n",
    "                  f\"loss_g:{g_loss.asnumpy():>4f} , \"\n",
    "                  f\"time:{(end1 - start1):>3f}s, \"\n",
    "                  f\"lr:{lr:>6f}\")\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"time of epoch {} is {:.2f}s\".format(epoch + 1, end - start))\n",
    "\n",
    "    losses_d.append(d_loss.asnumpy())\n",
    "    losses_g.append(g_loss.asnumpy())\n",
    "\n",
    "    # 每个epoch结束后，使用生成器生成一组图片\n",
    "    gen_imgs = net_g(test_noise)\n",
    "    save_imgs(gen_imgs.asnumpy(), epoch)\n",
    "\n",
    "    # 根据epoch保存模型权重文件\n",
    "    if epoch % 1 == 0:\n",
    "        save_checkpoint(net_g, checkpoints_path + \"/Generator%d.ckpt\" % (epoch))\n",
    "        save_checkpoint(net_d, checkpoints_path + \"/Discriminator%d.ckpt\" % (epoch))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 效果展示\n",
    "\n",
    "运行下面代码，描绘`D`和`G`损失与训练迭代的关系图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(losses_g, label=\"G\", color='blue')\n",
    "plt.plot(losses_d, label=\"D\", color='orange')\n",
    "plt.xlim(-20, 220)\n",
    "plt.ylim(0, 3.5)\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可视化训练过程中通过隐向量生成的图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "# 将训练过程中生成的测试图转为动态图\n",
    "image_list = []\n",
    "for i in range(total_epoch):\n",
    "    image_list.append(cv2.imread(image_path + \"/test_{}.png\".format(i), cv2.IMREAD_GRAYSCALE))\n",
    "show_list = []\n",
    "fig = plt.figure(dpi=70)\n",
    "for epoch in range(0, len(image_list), 5):\n",
    "    plt.axis(\"off\")\n",
    "    show_list.append([plt.imshow(image_list[epoch], cmap='gray')])\n",
    "\n",
    "ani = animation.ArtistAnimation(fig, show_list, interval=1000, repeat_delay=1000, blit=True)\n",
    "ani.save('train_test.gif', writer='pillow', fps=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![训练过程测试动态图](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.4.0/tutorials/source_zh_cn/generative/images/train_test.gif)\n",
    "\n",
    "从上面的图像可以看出，随着训练次数的增多，图像质量也越来越好。如果增大训练周期数，当 `epoch` 达到100以上时，生成的手写数字图片与数据集中的较为相似。下面我们通过加载生成器网络模型参数文件来生成图像，代码如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型推理\n",
    "\n",
    "下面我们通过加载生成器网络模型参数文件来生成图像，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore as ms\n",
    "\n",
    "test_ckpt = './result/checkpoints/Generator199.ckpt'\n",
    "\n",
    "parameter = ms.load_checkpoint(test_ckpt)\n",
    "ms.load_param_into_net(net_g, parameter)\n",
    "# 模型生成结果\n",
    "test_data = Tensor(np.random.normal(0, 1, (25, 100)).astype(np.float32))\n",
    "images = net_g(test_data).transpose(0, 2, 3, 1).asnumpy()\n",
    "# 结果展示\n",
    "fig = plt.figure(figsize=(3, 3), dpi=120)\n",
    "for i in range(25):\n",
    "    fig.add_subplot(5, 5, i + 1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(images[i].squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
