{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## MindNLP ChatGLM-6B StreamChat\n",
    "\n",
    "æœ¬æ¡ˆä¾‹åŸºäºMindNLPå’ŒChatGLM-6Bå®ç°ä¸€ä¸ªèŠå¤©åº”ç”¨ã€‚**æ”¯æŒæµå¼å›å¤**ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "è¯¥å®éªŒå¯è¿›è¡Œåœ¨çº¿ä½“éªŒï¼Œåœ¨çº¿ä½“éªŒé“¾æ¥ï¼ˆhttps://pangu.huaweicloud.com/gallery/asset-detail.html?id=cdc88c83-1ac2-4862-b822-3ab200b01736\n",
    "ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. æ•ˆæœå±•ç¤º\n",
    "\n",
    "\n",
    "<video controls width=\"500\" height=\"400\" src=\"https://mindspore-demo.obs.cn-north-4.myhuaweicloud.com/imgs/musicgen/chatglm6b-streamchat-demo.mp4\">animation</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 2. æ¡ˆä¾‹ä½“éªŒ\n",
    "ğŸ”¹ æœ¬æ¡ˆä¾‹éœ€ä½¿ç”¨ P100 åŠä»¥ä¸Šè§„æ ¼è¿è¡Œï¼Œè¯·ç¡®ä¿è¿è¡Œè§„æ ¼ä¸€è‡´ï¼Œå¯æŒ‰ç…§ä¸‹å›¾åˆ‡æ¢è§„æ ¼ã€‚\n",
    "\n",
    "![](https://modelarts-labs-bj4-v2.obs.cn-north-4.myhuaweicloud.com/case_zoo/chatglm3/image/1.png)\n",
    "\n",
    "ğŸ”¹ ç‚¹å‡»Run in ModelArtsï¼Œå°†ä¼šè¿›å…¥åˆ°ModelArts CodeLabä¸­ï¼Œè¿™æ—¶éœ€è¦ä½ ç™»å½•åä¸ºäº‘è´¦å·ï¼Œå¦‚æœæ²¡æœ‰è´¦å·ï¼Œåˆ™éœ€è¦æ³¨å†Œä¸€ä¸ªï¼Œä¸”è¦è¿›è¡Œå®åè®¤è¯ï¼Œå‚è€ƒ[ã€ŠModelArtså‡†å¤‡å·¥ä½œ_ç®€æ˜“ç‰ˆã€‹](https://developer.huaweicloud.com/develop/aigallery/article/detail?id=4ce709d6-eb25-4fa4-b214-e2e5d6b7919c) å³å¯å®Œæˆè´¦å·æ³¨å†Œå’Œå®åè®¤è¯ã€‚ ç™»å½•ä¹‹åï¼Œç­‰å¾…ç‰‡åˆ»ï¼Œå³å¯è¿›å…¥åˆ°CodeLabçš„è¿è¡Œç¯å¢ƒ\n",
    "\n",
    "ğŸ”¹ å‡ºç° Out Of Memory ï¼Œè¯·æ£€æŸ¥æ˜¯å¦ä¸ºæ‚¨çš„å‚æ•°é…ç½®è¿‡é«˜å¯¼è‡´ï¼Œä¿®æ”¹å‚æ•°é…ç½®ï¼Œé‡å¯kernelæˆ–æ›´æ¢æ›´é«˜è§„æ ¼èµ„æºè¿›è¡Œè§„é¿â—â—â—"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### 2.1 ç¯å¢ƒå®‰è£…\n",
    "\n",
    "\n",
    "è¿è¡Œå¦‚ä¸‹ä¸¤ä¸ªä»£ç å—ï¼Œåˆ›å»ºpython-3.9.0ç¯å¢ƒå¹¶åœ¨notebookçš„kernelæ˜¾ç¤ºé€‰é¡¹ã€‚\n",
    "\n",
    "> æ³¨æ„ï¼š\n",
    ">\n",
    "> æ­¤ä¸ºåœ¨çº¿è¿è¡Œå¹³å°é…ç½®python3.9çš„æŒ‡å—ï¼Œå¦‚åœ¨å…¶ä»–ç¯å¢ƒå¹³å°è¿è¡Œæ¡ˆä¾‹ï¼Œè¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹å¦‚ä¸‹ä»£ç ã€‚\n",
    ">\n",
    "> ä»¥ä¸‹ä¸¤ä¸ªä»£ç å—ä»…èƒ½è¿è¡Œä¸€æ¬¡ï¼Œå¤šæ¬¡è¿è¡Œä¼šå‡ºç°kernelæŠ¥é”™ã€‚\n",
    ">\n",
    "> å¦‚å‡ºç°å¤šæ¬¡è¿è¡Œå¯¼è‡´çš„kernelæŠ¥é”™ï¼Œè¯·ç»ˆæ­¢å®ä¾‹ï¼ˆç‚¹å‡»å³ä¸Šè§’â€œåœæ­¢NoteBookå®ä¾‹â€çš„åœ†å½¢å›¾æ ‡ï¼‰ï¼Œå¹¶é‡å¯å®ä¾‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "!/home/ma-user/anaconda3/bin/conda create -n python-3.9.0 python=3.9.0 -y --override-channels --channel https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\n",
    "!/home/ma-user/anaconda3/envs/python-3.9.0/bin/pip install ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "data = {\n",
    "   \"display_name\": \"python-3.9.0\",\n",
    "   \"env\": {\n",
    "      \"PATH\": \"/home/ma-user/anaconda3/envs/python-3.9.0/bin:/home/ma-user/anaconda3/envs/python-3.7.10/bin:/modelarts/authoring/notebook-conda/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/ma-user/modelarts/ma-cli/bin:/home/ma-user/modelarts/ma-cli/bin\"\n",
    "   },\n",
    "   \"language\": \"python\",\n",
    "   \"argv\": [\n",
    "      \"/home/ma-user/anaconda3/envs/python-3.9.0/bin/python\",\n",
    "      \"-m\",\n",
    "      \"ipykernel\",\n",
    "      \"-f\",\n",
    "      \"{connection_file}\"\n",
    "   ]\n",
    "}\n",
    "\n",
    "if not os.path.exists(\"/home/ma-user/anaconda3/share/jupyter/kernels/python-3.9.0/\"):\n",
    "    os.mkdir(\"/home/ma-user/anaconda3/share/jupyter/kernels/python-3.9.0/\")\n",
    "\n",
    "with open('/home/ma-user/anaconda3/share/jupyter/kernels/python-3.9.0/kernel.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "åˆ›å»ºå®Œæˆåï¼Œç¨ç­‰ç‰‡åˆ»ï¼Œæˆ–åˆ·æ–°é¡µé¢ï¼Œç‚¹å‡»å³ä¸Šè§’ï¼ˆæˆ–å·¦ä¸Šè§’ï¼‰kernelé€‰æ‹©python-3.9.0\n",
    "\n",
    "![change-kernel](https://mindspore-demo.obs.cn-north-4.myhuaweicloud.com/imgs/ai-gallery/change-kernel.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "pip install https://ms-release.obs.cn-north-4.myhuaweicloud.com/2.4.10/MindSpore/unified/aarch64/mindspore-2.4.10-cp39-cp39-linux_aarch64.whl --trusted-host ms-release.obs.cn-north-4.myhuaweicloud.com -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install mindnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio mdtex2html -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install ipywidgets -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture captured_output\n",
    "!wget -P /home/ma-user/work https://openi.pcl.ac.cn/lvyufeng/frpc-gradio/raw/branch/master/frpc_linux_amd64\n",
    "!cp /home/ma-user/work/frpc_linux_amd64 /home/ma-user/anaconda3/envs/python-3.9.0/lib/python3.9/site-packages/gradio/frpc_linux_amd64_v0.2\n",
    "!chmod +x /home/ma-user/anaconda3/envs/python-3.9.0/lib/python3.9/site-packages/gradio/frpc_linux_amd64_v0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 3. ä»£ç å¼€å‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindnlp.transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import gradio as gr\n",
    "import mdtex2html\n",
    "import mindspore\n",
    "\n",
    "# Ascendå¹³å°è¯·å–æ¶ˆä»¥ä¸‹æ³¨é‡Šï¼Œä½¿ç”¨åŠ¨æ€å›¾æ¨¡å¼\n",
    "mindspore.set_context(mode=mindspore.context.PYNATIVE_MODE,device_target='Ascend')\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('MindSpore-Lab/ChatGLM-6B', mirror=\"modelers\").half()\n",
    "model.set_train(False)\n",
    "tokenizer = AutoTokenizer.from_pretrained('MindSpore-Lab/ChatGLM-6B', mirror=\"modelers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'ä½ å¥½'\n",
    "history = []\n",
    "response, _ = model.chat(tokenizer, prompt, history=history, max_length=20)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, Union, Optional\n",
    "from typing import List\n",
    "\n",
    "\n",
    "import mdtex2html\n",
    "\n",
    "#å°†æ–‡æœ¬ä¸­çš„å­—ç¬¦è½¬ä¸ºç½‘é¡µä¸Šå¯ä»¥æ”¯æŒçš„å­—ç¬¦ï¼Œé¿å…è¢«è¯¯è®¤ä¸ºæ˜¯HTMLæ ‡ç­¾\n",
    "def parse_text(text):\n",
    "    \"\"\"copy from https://github.com/GaiZhenbiao/ChuanhuChatGPT/\"\"\"\n",
    "    lines = text.split(\"\\n\")\n",
    "    lines = [line for line in lines if line != \"\"]\n",
    "    count = 0\n",
    "    for i, line in enumerate(lines):\n",
    "        if \"```\" in line:\n",
    "            count += 1\n",
    "            items = line.split('`')\n",
    "            if count % 2 == 1:\n",
    "                lines[i] = f'<pre><code class=\"language-{items[-1]}\">'\n",
    "            else:\n",
    "                lines[i] = f'<br></code></pre>'\n",
    "        else:\n",
    "            if i > 0:\n",
    "                if count % 2 == 1:\n",
    "                    line = line.replace(\"`\", \"\\`\")\n",
    "                    line = line.replace(\"<\", \"&lt;\")\n",
    "                    line = line.replace(\">\", \"&gt;\")\n",
    "                    line = line.replace(\" \", \"&nbsp;\")\n",
    "                    line = line.replace(\"*\", \"&ast;\")\n",
    "                    line = line.replace(\"_\", \"&lowbar;\")\n",
    "                    line = line.replace(\"-\", \"&#45;\")\n",
    "                    line = line.replace(\".\", \"&#46;\")\n",
    "                    line = line.replace(\"!\", \"&#33;\")\n",
    "                    line = line.replace(\"(\", \"&#40;\")\n",
    "                    line = line.replace(\")\", \"&#41;\")\n",
    "                    line = line.replace(\"$\", \"&#36;\")\n",
    "                lines[i] = \"<br>\"+line\n",
    "    text = \"\".join(lines)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## 3.2 åŸºäº Gradio åˆ›å»ºèŠå¤©åº”ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¼–å†™Gradioè°ƒç”¨å‡½æ•°\n",
    "\n",
    "#é‡‡ç”¨æµèŠå¤©æ–¹å¼ï¼ˆstream_chatï¼‰è°ƒç”¨æ¨¡å‹ï¼Œä½¿å¾—ç”Ÿæˆç­”æ¡ˆæœ‰é€å­—ç”Ÿæˆçš„æ•ˆæœ\n",
    "def predict(input, chatbot, max_length, top_p, temperature, history):\n",
    "    chatbot.append((parse_text(input), \"\"))\n",
    "    for response, history in model.stream_chat(tokenizer, input, history, max_length=max_length, top_p=top_p,\n",
    "                                               temperature=temperature):\n",
    "        chatbot[-1] = (parse_text(input), parse_text(response))       \n",
    "\n",
    "        yield chatbot, history\n",
    "\n",
    "#å»é™¤è¾“å…¥æ¡†çš„å†…å®¹\n",
    "def reset_user_input():\n",
    "    return gr.update(value='')\n",
    "\n",
    "#æ¸…é™¤çŠ¶æ€\n",
    "def reset_state():\n",
    "    return [], [], None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#è¿è¡ŒGradioç•Œé¢ï¼Œè¿è¡ŒæˆåŠŸåç‚¹å‡»â€œRunning on public URLâ€åçš„ç½‘é¡µé“¾æ¥å³å¯ä½“éªŒ\n",
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.HTML(\"\"\"<h1 align=\"center\">MindNLP ChatGLM-6B StreamChat</h1>\"\"\")\n",
    "\n",
    "    chatbot = gr.Chatbot()\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=4):\n",
    "            with gr.Column(scale=12):\n",
    "                user_input = gr.Textbox(show_label=False, placeholder=\"Input...\", lines=3, container=False)\n",
    "            with gr.Column(min_width=32, scale=1):\n",
    "                with gr.Row():\n",
    "                    submitBtn = gr.Button(\"ä¸€é”®å¼€èŠ\", variant=\"primary\")\n",
    "                    emptyBtn = gr.Button(\"æ¸…é™¤å†å²\")\n",
    "            with gr.Column(scale=1):\n",
    "                max_length = gr.Slider(0, 4096, value=2048, step=1.0, label=\"Maximum length\", interactive=True)\n",
    "                top_p = gr.Slider(0, 1, value=0.7, step=0.01, label=\"Top P\", interactive=True)\n",
    "                temperature = gr.Slider(0, 1, value=0.95, step=0.01, label=\"Temperature\", interactive=True)               \n",
    "\n",
    "    history = gr.State([])\n",
    "\n",
    "    submitBtn.click(predict, [user_input, chatbot, max_length, top_p, temperature, history], [chatbot, history],\n",
    "                    show_progress=True)\n",
    "    submitBtn.click(reset_user_input, [], [user_input])\n",
    "\n",
    "    emptyBtn.click(reset_state, outputs=[chatbot, history], show_progress=True)\n",
    "\n",
    "demo.queue().launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "AIGalleryInfo": {
   "item_id": "cdc88c83-1ac2-4862-b822-3ab200b01736"
  },
  "flavorInfo": {
   "architecture": "X86_64",
   "category": "GPU"
  },
  "imageInfo": {
   "id": "e1a07296-22a8-4f05-8bc8-e936c8e54202",
   "name": "mindspore1.7.0-cuda10.1-py3.7-ubuntu18.04"
  },
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
