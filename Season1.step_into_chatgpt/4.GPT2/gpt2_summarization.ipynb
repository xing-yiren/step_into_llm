{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 基于MindSpore的GPT2文本摘要\n",
    "\n",
    "## 环境配置\n",
    "\n",
    "1. 配置python3.9环境\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "!/home/ma-user/anaconda3/bin/conda create -n python-3.9.0 python=3.9.0 -y --override-channels --channel https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\n",
    "!/home/ma-user/anaconda3/envs/python-3.9.0/bin/pip install ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "data = {\n",
    "   \"display_name\": \"python-3.9.0\",\n",
    "   \"env\": {\n",
    "      \"PATH\": \"/home/ma-user/anaconda3/envs/python-3.9.0/bin:/home/ma-user/anaconda3/envs/python-3.7.10/bin:/modelarts/authoring/notebook-conda/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/ma-user/modelarts/ma-cli/bin:/home/ma-user/modelarts/ma-cli/bin\"\n",
    "   },\n",
    "   \"language\": \"python\",\n",
    "   \"argv\": [\n",
    "      \"/home/ma-user/anaconda3/envs/python-3.9.0/bin/python\",\n",
    "      \"-m\",\n",
    "      \"ipykernel\",\n",
    "      \"-f\",\n",
    "      \"{connection_file}\"\n",
    "   ]\n",
    "}\n",
    "\n",
    "if not os.path.exists(\"/home/ma-user/anaconda3/share/jupyter/kernels/python-3.9.0/\"):\n",
    "    os.mkdir(\"/home/ma-user/anaconda3/share/jupyter/kernels/python-3.9.0/\")\n",
    "\n",
    "with open('/home/ma-user/anaconda3/share/jupyter/kernels/python-3.9.0/kernel.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "***注：以上代码执行完成后，需点击左上角或右上角将kernel更换为python-3.9.0***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "2. 安装mindspore2.2.12，安装指南详见：[MindSpore安装](https://www.mindspore.cn/install)\n",
    "3. 安装MindNLP及相关依赖，MindNLP官方仓详见：[MindNLP](https://github.com/mindspore-lab/mindnlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mindnlp-0.4.1-py3-none-any.whl  # 将安装mindnlp版本更换为mindnlp-0.4.0-py3-none-any.whl（daily版本）\n",
    "!pip install tokenizers==0.19.1 -i https://pypi.tuna.tsinghua.edu.cn/simple  # 修改tokenizers版本为0.19.1\n",
    "%env no_proxy='a.test.com,127.0.0.1,2.2.2.2'\n",
    "%pip install https://ms-release.obs.cn-north-4.myhuaweicloud.com/2.4.0/MindSpore/unified/aarch64/mindspore-2.4.0-cp39-cp39-linux_aarch64.whl --trusted-host ms-release.obs.cn-north-4.myhuaweicloud.com -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip uninstall mindformers -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "***注：执行如上命令完成安装后，请点击上方的restart kernel图标重启kernel，再进行实验***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### 数据集加载与处理\n",
    "\n",
    "1. 数据集加载\n",
    "\n",
    "    本次实验使用的是nlpcc2017摘要数据，内容为新闻正文及其摘要，总计50000个样本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindnlp.utils import http_get\n",
    "\n",
    "# download dataset\n",
    "url = 'https://download.mindspore.cn/toolkits/mindnlp/dataset/text_generation/nlpcc2017/train_with_summ.txt'\n",
    "path = http_get(url, './')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore.dataset import TextFileDataset\n",
    "\n",
    "# load dataset\n",
    "dataset = TextFileDataset(str(path), shuffle=False)\n",
    "dataset.get_dataset_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "**本案例默认在GPU P100上运行，因中文文本，tokenizer使用的是bert tokenizer而非gpt tokenizer等原因，全量数据训练1个epoch的时间约为80分钟。**\n",
    "\n",
    "**为节约时间，我们选取了数据集中很小的一个子集（500条数据）来演示gpt2的微调和推理全流程，但由于数据量不足，会导致模型效果较差。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing dataset\n",
    "mini_dataset, _ = dataset.split([0.001, 0.999], randomize=False)\n",
    "train_dataset, test_dataset = mini_dataset.split([0.9, 0.1], randomize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "2. 数据预处理\n",
    "\n",
    "    原始数据格式：\n",
    "    ```text\n",
    "    article: [CLS] article_context [SEP]\n",
    "    summary: [CLS] summary_context [SEP]\n",
    "    ```\n",
    "    预处理后的数据格式：\n",
    "\n",
    "    ```text\n",
    "    [CLS] article_context [SEP] summary_context [SEP]\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# preprocess dataset\n",
    "def process_dataset(dataset, tokenizer, batch_size=4, max_seq_len=1024, shuffle=False):\n",
    "    def read_map(text):\n",
    "        data = json.loads(text.tobytes())\n",
    "        return np.array(data['article']), np.array(data['summarization'])\n",
    "\n",
    "    def merge_and_pad(article, summary):\n",
    "        # tokenization\n",
    "        # pad to max_seq_length, only truncate the article\n",
    "        tokenized = tokenizer(text=article, text_pair=summary,\n",
    "                              padding='max_length', truncation='only_first', max_length=max_seq_len)\n",
    "        return tokenized['input_ids'], tokenized['input_ids']\n",
    "\n",
    "    dataset = dataset.map(read_map, 'text', ['article', 'summary'])\n",
    "    # change column names to input_ids and labels for the following training\n",
    "    dataset = dataset.map(merge_and_pad, ['article', 'summary'], ['input_ids', 'labels'])\n",
    "\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(batch_size)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "因GPT2无中文的tokenizer，我们使用BertTokenizer替代。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindnlp.transformers import BertTokenizer\n",
    "\n",
    "# We use BertTokenizer for tokenizing chinese context.\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = process_dataset(train_dataset, tokenizer, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(train_dataset.create_tuple_iterator())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### 模型构建\n",
    "\n",
    "1. 构建GPT2ForSummarization模型，注意***shift right***的操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改部分代码\n",
    "# from mindspore import ops\n",
    "# from mindnlp.transformers import GPT2LMHeadModel\n",
    "\n",
    "# class GPT2ForSummarization(GPT2LMHeadModel):\n",
    "#     def construct(\n",
    "#         self,\n",
    "#         input_ids = None,\n",
    "#         attention_mask = None,\n",
    "#         labels = None,\n",
    "#     ):\n",
    "#         outputs = super().construct(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         shift_logits = outputs.logits[..., :-1, :]\n",
    "#         shift_labels = labels[..., 1:]\n",
    "#         # Flatten the tokens\n",
    "#         loss = ops.cross_entropy(shift_logits.view(-1, shift_logits.shape[-1]), shift_labels.view(-1), ignore_index=tokenizer.pad_token_id)\n",
    "#         return loss\n",
    "from mindnlp.core.nn import functional as F\n",
    "from mindnlp.transformers import GPT2LMHeadModel\n",
    "\n",
    "class GPT2ForSummarization(GPT2LMHeadModel):\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids = None,\n",
    "        attention_mask = None,\n",
    "        labels = None,\n",
    "    ):\n",
    "        outputs = super().forward(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        shift_logits = outputs.logits[..., :-1, :]\n",
    "        shift_labels = labels[..., 1:]\n",
    "        # Flatten the tokens\n",
    "        loss = F.cross_entropy(shift_logits.view(-1, shift_logits.shape[-1]), shift_labels.view(-1), ignore_index=tokenizer.pad_token_id)\n",
    "        return (loss,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "2. 动态学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除了动态学习率\n",
    "\n",
    "# from mindspore import ops\n",
    "# from mindspore.nn.learning_rate_schedule import LearningRateSchedule\n",
    "\n",
    "# class LinearWithWarmUp(LearningRateSchedule):\n",
    "#     \"\"\"\n",
    "#     Warmup-decay learning rate.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, learning_rate, num_warmup_steps, num_training_steps):\n",
    "#         super().__init__()\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.num_warmup_steps = num_warmup_steps\n",
    "#         self.num_training_steps = num_training_steps\n",
    "\n",
    "#     def construct(self, global_step):\n",
    "#         if global_step < self.num_warmup_steps:\n",
    "#             return global_step / float(max(1, self.num_warmup_steps)) * self.learning_rate\n",
    "#         return ops.maximum(\n",
    "#             0.0, (self.num_training_steps - global_step) / (max(1, self.num_training_steps - self.num_warmup_steps))\n",
    "#         ) * self.learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "warmup_steps = 100\n",
    "learning_rate = 1.5e-4\n",
    "max_grad_norm = 1.0\n",
    "num_training_steps = num_epochs * train_dataset.get_dataset_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import nn\n",
    "from mindnlp.transformers import GPT2Config, GPT2LMHeadModel\n",
    "\n",
    "config = GPT2Config(vocab_size=len(tokenizer))\n",
    "model = GPT2ForSummarization(config)\n",
    "# 修改部分代码\n",
    "# lr_scheduler = LinearWithWarmUp(learning_rate=learning_rate, num_warmup_steps=warmup_steps, num_training_steps=num_training_steps)\n",
    "# optimizer = nn.AdamWeightDecay(model.trainable_params(), learning_rate=lr_scheduler)\n",
    "# optimizer = nn.AdamWeightDecay(model.trainable_params(), learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 记录模型参数数量\n",
    "print('number of model parameters: {}'.format(model.num_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改部分代码\n",
    "# from mindnlp._legacy.engine import Trainer\n",
    "# from mindnlp._legacy.engine.callbacks import CheckpointCallback\n",
    "\n",
    "# ckpoint_cb = CheckpointCallback(save_path='checkpoint', ckpt_name='gpt2_summarization',\n",
    "#                                 epochs=1, keep_checkpoint_max=2)\n",
    "\n",
    "# trainer = Trainer(network=model, train_dataset=train_dataset,\n",
    "#                   epochs=num_epochs, optimizer=optimizer, callbacks=ckpoint_cb)\n",
    "# trainer.set_amp(level='O1')  # 开启混合精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindnlp.engine import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"gpt2_summarization\",\n",
    "    save_steps=train_dataset.get_dataset_size(),\n",
    "    save_total_limit=3,\n",
    "    logging_steps=1000,\n",
    "    max_steps=num_training_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    warmup_steps=warmup_steps\n",
    "\n",
    ")\n",
    "\n",
    "from mindnlp.engine import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改部分代码\n",
    "# trainer.run(tgt_columns=\"labels\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_dataset(dataset, tokenizer, batch_size=1, max_seq_len=1024, max_summary_len=100):\n",
    "    def read_map(text):\n",
    "        data = json.loads(text.tobytes())\n",
    "        return np.array(data['article']), np.array(data['summarization'])\n",
    "\n",
    "    def pad(article):\n",
    "        tokenized = tokenizer(text=article, truncation=True, max_length=max_seq_len-max_summary_len)\n",
    "        return tokenized['input_ids']\n",
    "\n",
    "    dataset = dataset.map(read_map, 'text', ['article', 'summary'])\n",
    "    dataset = dataset.map(pad, 'article', ['input_ids'])\n",
    "\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_test_dataset = process_test_dataset(test_dataset, tokenizer, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(batched_test_dataset.create_tuple_iterator(output_numpy=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改部分代码\n",
    "# model = GPT2LMHeadModel.from_pretrained('./checkpoint/gpt2_summarization_epoch_0.ckpt', config=config)\n",
    "model = GPT2LMHeadModel.from_pretrained('./gpt2_summarization/checkpoint-45', config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "由于训练数据量少，epochs数少且tokenizer并未使用gpt tokenizer等因素，模型推理效果会较差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_train(False)\n",
    "model.config.eos_token_id = model.config.sep_token_id\n",
    "i = 0\n",
    "for (input_ids, raw_summary) in batched_test_dataset.create_tuple_iterator():\n",
    "    output_ids = model.generate(input_ids, max_new_tokens=50, num_beams=5, no_repeat_ngram_size=2)\n",
    "    output_text = tokenizer.decode(output_ids[0].tolist())\n",
    "    print(output_text)\n",
    "    i += 1\n",
    "    if i == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "AIGalleryInfo": {
   "item_id": "13ee0843-9209-4b5e-b99f-9ac05d1e0ed6"
  },
  "flavorInfo": {
   "architecture": "X86_64",
   "category": "GPU"
  },
  "imageInfo": {
   "id": "e1a07296-22a8-4f05-8bc8-e936c8e54202",
   "name": "mindspore1.7.0-cuda10.1-py3.7-ubuntu18.04"
  },
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
